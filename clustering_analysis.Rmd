---
title: "Cluster analysis of software mentions"
author: "James Howison and Caifan Du"
date: "10/12/2018"
output: html_document
---

```{r}
library(furrr)
library(intervals)
library(tidyverse)
library(here)
```


We suspect that the software mentions in a paper cluster together.  This would be useful to know because then we could do content analysis more quickly (because we wouldn't need to read as much of the paper in order to code mentions). We could use a "whitelist" of known package names to identify the "mention rich" parts of the papers, then code that.  But first we need to know what we might miss by making that change.

Procedure candidate:

On unseen papers:
1. Convert to fulltext
2. Search for "Seeds" taken from a whitelist of package names
3. Assign the text in a window around any seeds for content analysis (e.g., 500 words before and 500 words after, or 1 page before and 1 page after any seed found in the fulltext).

Analysis to see how this might perform:

1. Generate a whitelist of known package names as "seeds".
2. For each paper:
  - see if those seeds were mentioned, note PDF page where found.
  - query dataset for other mentions in that paper within X pages of where the seed was found.
  - recall = total found using seeds / total found in paper through manual coding (gives proportion of mentions that would have been included in the window.)
  - average recall across papers (or use a scatterplot)
3. Repeat for many possible random samples of seeds (and take the average as the expected recall value for each paper).

Repeat all that for varying window sizes (e.g., same page as seed, +/- 1 page, +/- 2 pages.)

Eventually we should get a curve showing the relationship between window size and recall.

load dataset.
```{r load_dataset}
articles <- read_csv(here("data/csv_dataset", "softcite_articles.csv"))
in_text_mentions <- read_csv(here("data/csv_dataset", "softcite_in_text_mentions.csv"))
codes_applied <- read_csv(here("data/csv_dataset", "softcite_codes_applied.csv"))
```


cross that with seeds so now we have a row for each paper/seed combination.  

search for those combinations.  could be in more than one spot in a paper.
paper,seed,seed_mention,pdf_page

(or start with full dataset, then filter out any that aren't our seeds)

add window sizes (can add all here)
paper,total_mention_count,seed,seed_mention,pdf_page,window_size,window_start,window_end

query others than would have been found. from each paper's set of mentions, which have a pdf page value such that: paper == paper, and window_start <= seed_pdf_page <= window_end. 

Then then have to merge the mentions found for each seed query.

Calculate recall for each paper.

Draw pretty pic.
-----------

Replanning at lunch.
Group by article
Nest mentions by article
turn into page list for mentions per article
add column which is page list for seeds, uniqued, in that article.
Expand seed page list to range using window size.
use interval overlap function across seed interval list and mention page list.
```{r}

count_mentions_in_window <- function(.seed_mentions_pages, .all_mentions_pages, .expand_window) {
  # print("seeds:")
  # print(dput(.seed_mentions_pages))
  # print("all_mentions")
  # print(dput(.all_mentions_pages))
  # print(.expand_window)
  
  # .seed_mentions_pages <- c(10,3,4,3)
  # .all_mentions_pages <- c(8,1,6,9,7,5,4,10,2,3)
  # .expand_window <- 1
  # .seed_mentions_pages <- list(3)
  # .all_mentions_pages <- list(3)
  # .expand_window <- 1
  if (length(.seed_mentions_pages) == 0 ||
      length(.all_mentions_pages) == 0) {
    to_ret <- as.integer(0)
  } else {
      to_ret <- generate_seed_interval(.seed_mentions_pages %>% unlist, .expand_window) %>% 
      # compares windows to points, returning matching indices.
      interval_overlap(.all_mentions_pages %>% unlist) %>% # returns a list of lists
      # seed 1 matches all_mention 1, 4, 5 (indexes from .all_mentions_pages list)
      unlist() %>% # removes empty lists (seeds that didn't match any, impossible anyway)
      unique() %>% # ensure each all_mention can only be counted once.
      length() 
  }
  
  # print(to_ret)
  # print("End count mentions call")
  return(to_ret)
}

safely_count_mentions_in_window <- safely(count_mentions_in_window)

# seed_pages <- .seed_mentions_pages
# expand_window <- .expand_window

generate_seed_interval <- function(seed_pages, expand_window) {
  tibble(from = seed_pages - expand_window,
           to = seed_pages + expand_window + 1) %>% 
      as.matrix %>% 
      # closed includes endpoints, open excludes.
      # This allows conseq pages to be merged during reduce.
      Intervals(closed = c(T,F)) %>% 
      intervals::reduce()
}

generate_seed_interval(list(3) %>% unlist,1)

```

```{r}


all_software_found <- codes_applied %>%
  drop_na(code_label) %>% 
  mutate(norm_code_label = code_label %>% str_to_lower()) %>%
  filter(code == "software_name", 
         was_code_present == "true") %>%
  select(-coder) %>%
  left_join(in_text_mentions, by = "selection") %>%
  select(article, selection, page, code_label, norm_code_label) %>% 
  drop_na(page)

all_seeds <- all_software_found %>% 
  select(norm_code_label) %>% 
  distinct()

# set up experiment.
experiment <- crossing(seed_percent = seq(0.05, 0.10, by = 0.05)) %>%
  crossing(replication = 1:25) %>% 
  # add seeds, resampling per experiment
  # needs tbl named as tbl is first argument to sample_frac
  mutate(curr_seeds = map(seed_percent, sample_frac, tbl = all_seeds))
```  


```{r}
options(future.globals.maxSize= 2048*1024^2)
plan(multiprocess)
# 1400 odd because those are the only articles with mentions.
full_experiment_results <- all_software_found %>% 
  # sample_n(10000) %>% 
  sample_frac(1) %>% 
  group_by(article, norm_code_label) %>% 
  summarize(page_for_label = list(page)) %>%
  # article, norm_code_label, pages
  # 1220303, hat, c(4,6,8)
  nest(-article, .key = article_label_pages) %>%
  # 1220303, tibble(norm_code_label = c("hat"), pages = c(4,6,8))
  mutate(article_mentions_pages = map(article_label_pages, pull, page_for_label),
         article_mentions_pages = map(article_mentions_pages, unique)) %>% 
  # set up experiments, each has its own set of seeds (inc. each replication)
  crossing(experiment) %>% 
  # expand_window, seed_percent, replication, curr_seeds, article, article_label_pages
  # which seed mentions are found in that article.
  mutate(seed_mentions = future_map2(article_label_pages, curr_seeds, inner_join, by = "norm_code_label", .progress = T)) %>% 
  # mutate(seed_mentions = map2(article_label_pages, curr_seeds, inner_join, by = "norm_code_label")) %>% 
  # expand_window, seed_percent, replication, curr_seeds, article, article_label_pages, seed_mentions
  # What unique pages were the seeds found on?
  mutate(seed_mentions_pages    = map(seed_mentions, pull, page_for_label),
         seed_mentions_pages    = map(seed_mentions_pages, unique)) %>%
  # drop unused columns
  select(-seed_mentions, -curr_seeds, -article_label_pages) %>% 
  # set up with different expand_window sizes.
  crossing(expand_window = seq(0, 20,length.out = 4) %>% floor) %>% 
  # custom function to see if page falls into interval implied by expand_window
  # pmap because each row has its own expand_window
  mutate(reachable_mentions = future_pmap(list(seed_mentions_pages,
                                            article_mentions_pages,
                                            expand_window),
                                       safely_count_mentions_in_window, .progress=T),
  # mutate(reachable_mentions       = pmap(list(seed_mentions_pages, 
  #                                           article_mentions_pages, 
  #                                           expand_window),
  #                                      safely_count_mentions_in_window),
         reachable_mentions_count = map_int(reachable_mentions, pluck, "result"),
         total_mentions           = map_int(article_mentions_pages, length),
         reached_proportion       = reachable_mentions_count / total_mentions)
```

```{r}
summarized_results <- full_experiment_results %>% 
  mutate(expand_window = parse_factor(expand_window, levels=NULL)) %>% 
  # collapse replications
  group_by(expand_window, seed_percent) %>% 
  summarize(mean_proportion = mean(reached_proportion))

summarized_results %>% 
  ggplot(aes(x = seed_percent, y = mean_proportion, group = expand_window, color = expand_window)) +
  # scale_color_brewer(type="div", palette = "RdPu") 
  geom_point() +
  geom_line() +
  scale_color_viridis_d(option="C") +
  guides(colour = guide_legend(reverse=T))
```

```{r}
# test_seeds <- c(1, 5)
# test_expand <- 1
# test_all <- c(2)
# 
# tibble(from = test_seeds - test_expand,
#            to = test_seeds + test_expand + 1) %>% 
#       as.matrix %>% 
#       # closed includes endpoints
#       Intervals(closed = c(T,F)) %>% 
#       intervals::reduce() %>% # minimize intervals
#       print() %>% 
#       # compares windows to points, returning matching indices.
#       interval_overlap(test_all)
```

