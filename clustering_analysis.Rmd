---
title: "Cluster analysis of software mentions"
author: "James Howison and Caifan Du"
date: "10/12/2018"
output: html_document
---

```{r}
library(furrr)
library(intervals)
library(tidyverse)
library(here)
```


We suspect that the software mentions in a paper cluster together.  This would be useful to know because then we could do content analysis more quickly (because we wouldn't need to read as much of the paper in order to code mentions). We could use a "whitelist" of known package names to identify the "mention rich" parts of the papers, then code that.  But first we need to know what we might miss by making that change.

Procedure candidate:

On unseen papers:
1. Convert to fulltext
2. Search for "Seeds" taken from a whitelist of package names
3. Assign the text in a window around any seeds for content analysis (e.g., 500 words before and 500 words after, or 1 page before and 1 page after any seed found in the fulltext).

Analysis to see how this might perform:

1. Generate a whitelist of known package names as "seeds".
2. For each paper:
  - see if those seeds were mentioned, note PDF page where found.
  - query dataset for other mentions in that paper within X pages of where the seed was found.
  - recall = total found using seeds / total found in paper through manual coding (gives proportion of mentions that would have been included in the window.)
  - average recall across papers (or use a scatterplot)
3. Repeat for many possible random samples of seeds (and take the average as the expected recall value for each paper).

Repeat all that for varying window sizes (e.g., same page as seed, +/- 1 page, +/- 2 pages.)

Eventually we should get a curve showing the relationship between window size and recall.

load dataset.
```{r load_dataset}
articles <- read_csv(here("data/csv_dataset", "softcite_articles.csv"))
in_text_mentions <- read_csv(here("data/csv_dataset", "softcite_in_text_mentions.csv"))
codes_applied <- read_csv(here("data/csv_dataset", "softcite_codes_applied.csv"))
```


cross that with seeds so now we have a row for each paper/seed combination.  

search for those combinations.  could be in more than one spot in a paper.
paper,seed,seed_mention,pdf_page

(or start with full dataset, then filter out any that aren't our seeds)

add window sizes (can add all here)
paper,total_mention_count,seed,seed_mention,pdf_page,window_size,window_start,window_end

query others than would have been found. from each paper's set of mentions, which have a pdf page value such that: paper == paper, and window_start <= seed_pdf_page <= window_end. 

Then then have to merge the mentions found for each seed query.

Calculate recall for each paper.

Draw pretty pic.
-----------

Replanning at lunch.
Group by article
Nest mentions by article
turn into page list for mentions per article
add column which is page list for seeds, uniqued, in that article.
Expand seed page list to range using window size.
use interval overlap function across seed interval list and mention page list.
```{r}

count_mentions_in_window <- function(.seed_mentions_pages, .all_mentions_pages, .expand_window) {
  # print("seeds:")
  # print(dput(.seed_mentions_pages))
  # print("all_mentions")
  # print(dput(.all_mentions_pages))
  # print(.expand_window)
  
  # .seed_mentions_pages <- c(10,3,4,3)
  # .all_mentions_pages <- c(8,1,6,9,7,5,4,10,2,3)
  # .expand_window <- 1
  .seed_mentions_pages <- list()
  .all_mentions_pages <- list(3)
  .expand_window <- list(0,5,10)
  if (length(.seed_mentions_pages) == 0 ||
      length(.all_mentions_pages) == 0) {
    to_ret <- tibble(
      expand_window = .expand_window,
      mentions_in_window = rep_along(.expand_window, 0)
    )
  } else {
      to_ret <- tibble(
        seed_pages = .seed_mentions_pages %>% unlist,
        expand_window = .expand_window %>% unlist
      ) %>% 
        mutate(expand_interval = map2(seed_pages, expand_window, generate_seed_interval)) %>% 
        map2(.all_mentions_pages %>% unlist, interval_overlap) %>% 
        map(unlist) %>% 
        map(unique) %>% 
        map(sum)
      # to_ret <- pmap(seed_pagesxpand_window)
      #   generate_seed_interval(, .expand_window %>% unlist) %>% 
      # compares windows to points, returning matching indices.
      interval_overlap(.all_mentions_pages %>% unlist) %>% # returns a list of lists
      # seed 1 matches all_mention 1, 4, 5 (indexes from .all_mentions_pages list)
      unlist() %>% # removes empty lists (seeds that didn't match any, impossible anyway)
      unique() %>% # ensure each all_mention can only be counted once.
      length() 
  }
  
  # print(to_ret)
  # print("End count mentions call")
  return(to_ret)
}

# safely_count_mentions_in_window <- safely(count_mentions_in_window)
# 
# seed_pages <- .seed_mentions_pages %>% unlist
# expand_window <- .expand_window %>% unlist
# 
# # this needs to run once per item sent in expand_window
# # receive list of expand window, return table with expand_window, count_mentions
# #                                                      5, 4
# generate_seed_interval <- function(seed_pages, expand_window_single) {
#   tibble(from = seed_pages - expand_window_single,
#            to = seed_pages + expand_window_single + 1) %>% 
#       as.matrix %>% 
#       # closed includes endpoints, open excludes.
#       # This allows conseq pages to be merged during reduce.
#       Intervals(closed = c(T,F)) %>% 
#       intervals::reduce()
# }
# 
# generate_seed_interval(list(3) %>% unlist, c(3,4,5))

```

```{r}


all_software_found <- codes_applied %>%
  drop_na(code_label) %>% 
  mutate(norm_code_label = code_label %>% str_to_lower()) %>%
  filter(code == "software_name", 
         was_code_present == "true") %>%
  select(-coder) %>%
  left_join(in_text_mentions, by = "selection") %>%
  select(article, selection, page, code_label, norm_code_label) %>% 
  drop_na(page)

all_seeds <- all_software_found %>% 
  select(norm_code_label) %>% 
  distinct()

# set up experiment.
experiment <- crossing(seed_percent = seq(0.05, 1, by = 0.05)) %>%
  crossing(replication = 1:25) %>% 
  # add seeds, resampling per experiment
  # needs tbl named as tbl is first argument to sample_frac
  mutate(curr_seeds = map(seed_percent, sample_frac, tbl = all_seeds))

# Need article, seed_pages, mention_pages.
expand_window <- seq(0, 20,length.out = 4) %>% floor
expand_window <- 1 * 1.7^(0:10) %>% 
  ceiling %>% 
  unique %>% 
  discard(~ .x > max(all_software_found$page))
expand_window = 0:1
```  


```{r}
# for each combination of seed and mention, calculate absolute value distance.
# see if >= window size.


window_size <-  list(0,1,2,10)
mention_page <-  list(4,7,9,10)
seed_page <-  list(10)

count_reached_in_window <- function(seed_page, mention_page, expand_window) {
  if (length(seed_page) == 0 ||
      length(mention_page) == 0) {
    return(tibble(
      expand_window = expand_window,
      reached_proportion = as.double(0)
    ))
  } else {
    seed_page <- seed_page %>% unlist
    mention_page <- mention_page %>% unlist
    expand_window <- expand_window %>% unlist
    
    crossing(seed_page, mention_page) %>%
      mutate(diff = abs(seed_page - mention_page)) %>%
      crossing(expand_window) %>% 
      mutate(in_window = expand_window >= diff) %>% 
      group_by(expand_window) %>% 
      summarize(reached_proportion = sum(in_window) / n())
  }
}

safely_count_reached_in_window <- safely(count_reached_in_window)

# if it's in a smaller window size, it's definitely in a larger one. Something to do with reduce.

safely_count_reached_in_window(seed_page, mention_page, window_size)
safely_count_reached_in_window(list(), mention_page, window_size)


```

```{r}
options(future.globals.maxSize= 2048*4*1024^2)
plan(multiprocess)


install.packages("sparklyr") %>% 
  # set up experiments, each has its own set of seeds (inc. each replication)
  crossing(experiment) %>% 
  mutate(expand_window = list(expand_window)) %>% 
  # expand_window, seed_percent, replication, curr_seeds, article, article_label_pages
  # which seed mentions are found in that article.
  mutate(seed_mentions = future_map2(article_label_pages, curr_seeds, inner_join, 
                                     by = "norm_code_label", .progress = T)) %>% 
  # What unique pages were the seeds found on?
  mutate(seed_mentions_pages    = map(seed_mentions, pull, page_for_label),
         seed_mentions_pages    = map(seed_mentions_pages, unique)) %>%
  # drop unused columns
  select(-seed_mentions, -curr_seeds, -article_label_pages) %>% 
  mutate(reached_call = future_pmap(list(seed_mentions_pages,
                                            article_mentions_pages,
                                            expand_window),
                                       safely_count_reached_in_window, .progress=T),
         reached_proportions = map(reached_call, pluck, "result")) %>% 
  unnest(reached_proportions)

```

```{r}
software_by_page <- all_software_found %>% 
  # sample_n(10000) %>% 
  sample_frac(0.20) %>% 
  group_by(article, norm_code_label) %>% 
  summarize(page_for_label = list(page))

```



```{r}
summarized_results <- full_experiment_results %>% 
  mutate(expand_window = parse_factor(expand_window, levels=NULL)) %>% 
  # collapse replications
  group_by(expand_window, seed_percent) %>% 
  summarize(mean_proportion = mean(reached_proportion))

summarized_results %>% 
  ggplot(aes(x = seed_percent, y = mean_proportion, group = expand_window, color = expand_window)) +
  # scale_color_brewer(type="div", palette = "RdPu") 
  geom_point() +
  geom_line() +
  scale_color_viridis_d(option="C") +
  guides(colour = guide_legend(reverse=T))
```

```{r}
summarized_results <- full_experiment_results %>% 
  mutate(expand_window = parse_factor(expand_window, levels=NULL)) %>% 
  group_by(expand_window, seed_percent, replication) %>% 
  summarize(mean_proportion = mean(reached_proportion))

summarized_results %>% 
  ggplot(aes(x = seed_percent, y = mean_proportion, group = expand_window, color = expand_window)) +
  # scale_color_brewer(type="div", palette = "RdPu") 
  geom_point(position = position_jitter(width=0.01), alpha=0.8) +
  # geom_line() +
  scale_color_viridis_d(option="C") +
  guides(colour = guide_legend(reverse=T))
```

```{r}
expand_window <- c(0,1,2,10)
window_breaks <-  c(0,sort(expand_window))
mention_page <-  c(4,7,9,10)
seed_page <-  c(10, 4)

tibble(windows = expand_window,
       counts = crossing(seed_page, mention_page) %>%
                  mutate(diff = abs(seed_page - mention_page)) %>%
                  pull(diff) %>% 
                  hist(window_size, plot = FALSE) %>% 
                  pluck("counts") %>% 
                  cumsum() # things in lower windows are in higher windows.
)

```

use the seeds and the expand_windows to create breaks.

```{r}
expand_window <- c(0,1,2,10)
window_breaks <-  c(0,sort(expand_window))
mention_page <-  c(4,7,9,10)
seed_page <-  c(10, 4)

crossing(expand_window, seed_page)
```

0: (4,4) (10,10)
1: (3,5) (9,11)
2: (2,6), (8,12)

Create a table per article of mention to mention distances.

from_selection_id, from_selection_norm_code_label, from_selection_page, to_selection_id, to_selection_norm_code_label, to_selection_page, distance

Filter that to find reachable mentions, given a starting norm_code_label, and a set of window sizes.

```{r}
library(cluster)
library(janitor)
library(furrr)

options(future.globals.maxSize= 2048*4*1024^2)
plan(multiprocess)

quietly_daisy <- quietly(daisy)
quietly_tidy_daisy <- quietly(tidy_daisy)

# test_frame <- test_frame[[1]]

# my_tibl <- test_frame

tidy_daisy <- function(my_tibl) {
  sel_names <- my_tibl %>% pull(sel_name)
  df <- as.data.frame(my_tibl %>% select(page))
  row.names(df) <- sel_names
  # have to return Differences object in a list or dplyr/purrr screws with it
  # something to do with column name hate.
  list(daisy(df, metric = "euclidean")) # %>% as.matrix %>% as.data.frame %>% rownames_to_column()
}


dist_matrices <- all_software_found %>%
  mutate(norm_code_label = norm_code_label %>% str_replace_all("\\s", "---")) %>% 
  unite(sel_name, selection, norm_code_label, sep = "~~") %>% 
  select(-code_label) %>%
  distinct() %>% 
  nest(-article, .key = software_found) %>% 
 # slice(4:4) %>% 
  # pull(software_found)
  transmute(article     = article,
            dist_result = map(software_found, tidy_daisy))
  # mutate(dist_result = future_map(software_found, quietly_tidy_daisy, .progress = T))

```

```{r}


make_long <- function(dist_list) {
  simm = dist_list[[1]]
  simm %>% 
    as.matrix %>% 
    as.data.frame %>% 
    rownames_to_column() %>% 
    gather(key = "to_selection", "page_diff", -rowname) %>% 
    separate(to_selection, into = c("to_selection", "to_norm_code_label"), sep = "~~") %>% 
    separate(rowname, into = c("selection", "norm_code_label"), sep = "~~") %>%
    mutate(norm_code_label = str_replace_all(norm_code_label, "---", " "),
           to_norm_code_label = str_replace_all(to_norm_code_label, "---", " ")) %>% 
    filter(selection != to_selection) %>% 
    as.tibble
}

long_result <- dist_matrices %>% 
  transmute(article = article,
            long_result = map(dist_result, make_long))

long_result %>% slice(2:2) %>% pull(long_result) %>% pluck(1)
```



```{r}
expand_window <- seq(0, 20,length.out = 4) %>% floor
expand_window <- 1 * 1.7^(0:10) %>% 
  ceiling %>% 
  unique %>% 
  discard(~ .x > max(all_software_found$page))
expand_window <- 0:1

# set up experiment.
experiment <- crossing(seed_percent = seq(0.05, 1, by = 0.05)) %>%
  crossing(replication = 1:1) %>% 
  # add seeds, resampling per experiment
  # needs tbl named as tbl is first argument to sample_frac
  mutate(curr_seeds = map(seed_percent, sample_frac, tbl = all_seeds))




```

Using these long tables.  For each seed, for each expand_window, which others are within page_dist <= expand_window

To do all at once it's an inequality join.

```{r}
options(future.globals.maxSize= 2048*4*1024^2)
plan(multiprocess)

experiment_with_data <- long_result %>% 
  crossing(experiment)

curr_long_result <- experiment_with_data %>% slice(1:1) %>% pull(long_result) %>% pluck(1)
curr_seeds <- experiment_with_data %>% slice(1:1) %>% pull(curr_seeds) %>% pluck(1)

filter_seeds <- function(single_window, seed_starts) {
  seed_starts %>% 
    filter(page_diff <= single_window) %>% 
    nrow()
}

# expand_window is a list outside the dataframe
find_reached <- function(curr_long_result, curr_seeds) {
  seed_starts <- inner_join(curr_seeds, curr_long_result, by = "norm_code_label")
  # find seed rows.
  
  # do mention counts by cutting distribution of page_diff on expand_window
  # c(0) ensures that the first window is from diff 0 to greater
  counts <- hist(seed_starts$page_diff, c(0,expand_window), plot = FALSE) %>% 
                  pluck("counts") %>% 
                  cumsum() # things in lower windows are in higher windows.  
  as.tibble(list(expand_window = expand_window,
                 reached_in_window = counts))
    # as.tibble(list(expand_window = expand_window)) %>%
    #   # single parameter map call, seed_starts passed over each time as parameter
    #   mutate(reached_in_window = map_int(expand_window, filter_seeds, seed_starts))
    #   
}


find_reached(experiment_with_data %>% slice(1:1) %>% pull(long_result) %>% pluck(1), 
             experiment_with_data %>% slice(1:1) %>% pull(curr_seeds) %>% pluck(1))

results_of_experiment <- experiment_with_data %>% 
  mutate(
    reached_count  = future_pmap(list(long_result, curr_seeds), find_reached, .progress = T),
         total_mentions = map_int(long_result, nrow)) %>% 
  unnest(reached_count) %>% 
  # if_else to avoid division of 0 / 0
  mutate(reached_proportion = if_else(total_mentions == 0, 0, reached_in_window / total_mentions))
```

```{r}
# results_of_experiment %>% summary
# 
# results_of_experiment %>% filter(reached_proportion %>% is.na)

summarized_results <- results_of_experiment %>% 
  mutate(expand_window = parse_factor(expand_window, levels=NULL)) %>% 
  group_by(expand_window, seed_percent, replication) %>% 
  summarize(mean_proportion = mean(reached_proportion))

summarized_results %>% 
  ggplot(aes(x = seed_percent, y = mean_proportion, group = expand_window, color = expand_window)) +
  # scale_color_brewer(type="div", palette = "RdPu") 
  geom_point(position = position_jitter(width=0.01), alpha=0.8) +
  # geom_line() +
  scale_color_viridis_d(option="C") +
  guides(colour = guide_legend(reverse=T))
```

